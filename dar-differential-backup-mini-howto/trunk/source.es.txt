=========================================
 DAR differential backup mini-howto -EN-
=========================================

:Author: Grzegorz Adam Hankiewicz
:Contact: gradha@titanium.sabren.com
:Translator: Grzegorz Adam Hankiewicz
:Date: $Date$
:Version: H1 ($Rev$ under Subversion_ control)
:Web site: http://gradha.sdf-eu.org/textos/backup.es.html
:Copyright: Este documento está bajo dominio público.
:Translations: De la página web puede obtener este documento en
               inglés, italiano y español.

.. contents::
.. _Bzip2: http://sources.redhat.com/bzip2/
.. _cdrecord: http://www.fokus.fhg.de/research/cc/glone/employees/joerg.schilling/private/cdrecord.html
.. _DAR: http://dar.linux.free.fr/
.. _Freshmeat: http://freshmeat.net/
.. _Knoppix: http://www.knoppix.org/
.. _rsync: http://rsync.samba.org/
.. _ssh: http://www.openssh.com/
.. _Subversion: http://subversion.tigris.org/
.. _tar: http://freshmeat.net/projects/tar/
.. _Tripwire: http://www.tripwire.org/


Introducción
============

   Todos deberíamos hacer copias de seguridad de nuestros datos
   importantes.  Este consejo omnipresente es habitualmente ignorado
   por la mayoría de las personas. Yo lo ignoré también, hasta que
   perdí una buena cantidad de datos importantes. Insatisfecho,
   continué perdiendo datos en algunos incidentes posteriores,
   hasta que decidí que era bastante. Entonces busqué programas de
   copias de seguridad en Freshmeat_ que permitiesen hacer copias
   de seguridad diferenciales y encontré DAR_.

   Una copia de seguridad completa significa que todos los ficheros
   bajo su política de seguridad serán guardados. Una copia de
   seguridad diferencial o incremental, sólo contendrá aquellos
   ficheros cuyos contenidos han cambiado desde la copia de seguridad
   anterior, ya sea esta completa o diferencial.

   DAR_ le permite crear de forma sencilla un cojunto de copias de
   seguridad diferenciales. El método que he resarrollado me ayuda
   a tener copias de seguridad automáticas que se ejecutan cada
   noche.  El primer día del mes, se realiza una copia de seguridad
   completa.  El resto del mes, sólo se realizan copias de seguridad
   diferenciales.  En mi situación, muy pocos ficheros cambian de
   un día a otro, algunas veces el código fuente del proyecto en
   el que estoy trabajando, y siempre mis buzones de correo.

   El resultado es que puedo recuperar el contenido de mi ordenador
   a un día específico con facilidad, en caso de necesitarlo. DAR_
   es un programa de línea de comando, y puede hacerse ligeramente
   complejo con algunas opciones. Este pequeño mini-howto le
   explicará mi solución personal, que es muy cruda, pero me da
   buenos resultados.  Si, he verificado que puedo recuperar datos
   de las copias de seguridad.  De hecho, a finales del año 2003 me
   transladé a otro país y sólamente llevé conmigo un CD ROM con
   una Knoppix_ autoarrancable, y recuperé el estado exacto de mi
   instalación Debian en cuestión de horas.  Sin personalizaciones,
   sin largas instalaciones, sin ficheros perdidos.

   Este documento fue escrito usando la versión 1.3.0 de DAR_. Cuando
   me actualicé a DAR 2.0.3, todo seguía funcionando, ni si quiera
   tuve que actualizar mis archivos de copias de seguridad. Así
   que parece que la interfaz y el formato de copias de seguridad
   son bastante estables, o almenos compatibles hacia atrás. No
   obstante, no confíe a ciegas en este documento. Verifique que la
   versión de DAR_ que tiene instalada funciona como espera y que
   puede recuperar una copia de seguridad generada antes de tener
   que depender de ella.

   Esta versión del texto usa reStructuredText (para eso son las
   marcas extrañas en la versión en modo texto). Lea más sobre esto
   en http://docutils.sourceforge.net/.


Uso simple de DAR
=================

   DAR_ es muy similar a tar_ en el número de opciones que tiene: hay
   suficiente para cada necesidad, pero demasiadas para un novato.
   Como es habitual, siempre puede obtener ayuda del programa
   tecleando ``dar -h`` o ``man dar`` tras su instalación. Al
   igual que tar_, hay un conjunto de parámetros obligatorios que
   definen el tipo de operación que va a realizar (crear, extraer,
   listar, etc), y un conjunto de parámetros que afectan la opción
   seleccionada. Simplemente por probar, imagínese que quiere
   realizar una copia de seguridad de su directorio home. Escribiría
   algo así::

      dar -c fichero_sin_extension file1 file2 ... fileN

   La salida debería ser similar a esto::

      $ dar -c mi_copia safecopy.py/ translate_chars.py/
      
      
       --------------------------------------------
       15 inode(s) saved
       with 0 hard link(s) recorded
       0 inode(s) not saved (no file change)
       0 inode(s) failed to save (filesystem error)
       4 files(s) ignored (excluded by filters)
       0 files(s) recorded as deleted from reference backup
       --------------------------------------------
       Total number of file considered: 19
      $ ls
      mailbox_date_trimmer/  mi_copia.1.dar        sdb.py/
      mailbox_reader/        safecopy.py/          translate_chars.py/

   Tal y como se habrá dado cuenta, DAR_ añade un número y extensión
   a su nombre. El propósito de la extensión es claro, ayuda a saber
   visualmente que el fichero es una copia de seguridad de DAR_. El
   número es un *trozo*, y está relacionada con la característica
   de DAR_ de repartir la copia de seguridad en varios dispositivos
   de almacenamiento.  Si por ejemplo quisiese hacer una copia de
   seguridad en CD ROM, pero sus directorios son mayores que la
   capacidad de uno, puede decirle a DAR_ que reparta el archivo
   en tantos ficheros como sea necesario, que luego puede grabar
   en varios CD ROMs.

   ¿Quiere recuperar su copia de seguridad? Muy sencillo, teclée
   lo siguiente::

      $ mkdir temp
      $ cd temp
      $ dar -x ../my_backup_file
      file ownership will not be restored as dar is not run as root.
      to avoid this message use -O option [return = OK | esc = cancel]
      Continuing...
      
      
       --------------------------------------------
       15 file(s) restored
       0 file(s) not restored (not saved in archive)
       0 file(s) ignored (excluded by filters)
       0 file(s) less recent than the one on filesystem
       0 file(s) failed to restore (filesystem error)
       0 file(s) deleted
       --------------------------------------------
       Total number of file considered: 15
      $ ls
      safecopy.py/  translate_chars.py/
      

La estrategia de copias de seguridad
====================================

   El primer paso para crear una buena copia de seguridad es
   determinar qué partes de su sistema necesitan una. Esto
   no significa necesariamente que no puede crear una copia de
   seguridad completa, sólo que repartir la copia en al menos dos
   partes puede ayudar mucho a DAR_ (y cualquier otra herramienta
   de copias de seguridad).

   Mi sistema en casa se compone de dos discos duros. El primero
   está partido en una partición de 3.8 GB donde vive mi sistema
   completo, y otra partición de 11 GB donde almaceno mi música y
   otros ficheros temporales, como un repositorio local de paquetes
   Debian que hago para mí mismo.  El segundo disco duro tiene
   una partición de 9.4 GB cuyo único propósito es servir de copia
   de seguridad del disco primario. No tengo interés en realizar
   copias de seguridad de mi música, porque tengo todos los CDs
   originales y scripts para recomprimirlos en formato ogg.

   De las 3.8 GB que quiero hacer copia de seguridad, normalmente
   entre 1.3 y 1.5 GB están vacías. Repartiré las 2.3 GB usadas
   a nivel lógico entre directorios de *sistema* y *home* (en el
   momento de escribir esto, mi home ocupa 588 MB). La razón de
   esta separacio es que como usuario normal sólo puedo cambiar
   cosas en mi directorio home y otros ficheros de las particiones
   que no hago copias de seguridad.  Mientras, la parte *sistema*
   de la partición es bastante estable y no se modifica porque
   (des)instalo software muy de vez en cuando.  De hecho, de mi
   directorio *home* las únicas cosas que cambian normalmente
   son mis directorios ``Mail`` y ``projects``, donde pongo este
   documento y otro software que escribo/hackeo.

   La diferenciación básica entre *directorios home* y *de sistema*
   también puede ser útil en organizaciones. Si trabaja para una
   universidad, normalmente todas las máquinas tendrán la misma
   configuración de sistema, pero dependiendo de la máquina sus
   directorios home contendrán datos diferentes. Puede hacer un a
   *copia de seguridad de sistema* de una sola máquina, y *copias
   de seguridad del home* de cada máquina. Otra configuración común
   es tener un servidor central que exporta los directorios home por
   NFS. Aquí sólo tiene que hacer copia de seguridad del servidor. Si
   tiene usuarios con privilegios altos, déjeles la tarea de hacer
   una *copia de seguridad de sistema* de sus propias máquinas,
   el directorio home exportado es algo que pueden ignorar dado
   que será realizado en el servidor.

   Una vez haya decidido qué quiere guardar en su copia de seguridad,
   debe decidir cómo configurar DAR_. Puede usar parámetros o
   ficheros de configuración. Los parámetros están bien cuando no
   tiene muchas opciones. Los ficheros de configuración son mejores
   cuando quiere añadir complejas reglas de inclusión/exclusión de
   ficheros, y además, puede usar comentarios para documentar los
   parámetros, indicando por ejemplo la razón por la que incluye
   tal o cual directorio. Esto puede ser útil si vuelve dentro de
   unos meses y se pregunta qué hacen todas estas opciones.

   Con mi configuración, ejecutaré comandos DAR_ desde scripts shell
   llamados periódicamente por cron (`Configurando algunos scripts
   para automatizar el proceso`_), así que no me importa tener
   largas líneas de comando, y este mismo documento tiene doble
   propósito para documentar esos scripts. Si prefiere ficheros
   de configuración, lea la documentación de DAR para aprender su
   formato y cómo usarlos.


Copia de seguridad completa con DAR
===================================

   Aquí está la línea de comando completa que usaré para mi copia de
   seguridad de *sistema*, ejecutada como **root**. No se preocupe
   por el gran número de parámetros, iré describiéndo su propósito
   uno a uno::

      dar -m 256 -y -s 600M -D -R / -c `date -I`_data -Z "*.gz" \
         -Z "*.bz2" -Z "*.zip" -Z "*.png" -P home/gregorio -P tmp \
         -P mnt -P dev/pts -P proc -P floppy -P burner -P cdrom

   * ``-m 256``
      DAR_ puede comprimir su copia de seguridad. La compresión
      se aplica a ficheros individuales, y puede ser perjudicial
      para pequeños ficheros. Por defecto los ficheros con 100
      bytes o menos no serán comprimidos. Con el parámetro ``-m``
      incremento este valor a 256, el cual parece funcionar mejor
      para esos pequeños ficheros de configuración que se almacenan
      en ``/etc/`` y ``/home``. Como puede ver, esta opción es
      completamente opcional, básicamente para fanáticos del ajuste
      como yo.
      
   * ``-y [nivel]``
      Esta opción activa la compresión Bzip2_ del archivo, que por
      defecto está desactivada. Incluso puede especificar un nivel
      numérico de compresión, que va de 0 (no compresión) hasta
      9 (mejor compresión, procesado lento). Bzip2_ por defecto
      usa 6, que es la mejor relación velocidad/compresión para
      la mayoría de los ficheros. Yo no uso nivel de compresión,
      el 6 me va bien.

   * ``-s 600M``
      Aquí está la característica de DAR_ de trocear. El tamaño
      especificado de 600 Megabytes es el tamaño máximo de fichero
      que DAR_ creará. Si su copia de seguridad es mayor, obtendrá
      varios ficheros de copia de seguridad, cada uno con su número
      de trozo antes de la extensión del fichero, para que pueda
      salvar cada uno en una unidad diferente de almacenamiento
      (disquetes, zip, CDROM, etc). Mis copias de seguridad son
      mucho más pequeñas que este tamaño, y mantengo este parámetro
      sólo por si acaso se me ocurre crear un fichero grande en
      mi directorio home y olvido borrarlo. Si este parámetro
      le resulta útil, lea también en el manual de DAR_ sobre el
      parámetro ``-S``.

   * ``-D``
      Stores directories excluded by the ``-P`` option or absent
      from the command line path list as empty directories. This
      is helpful when you are recovering a backup from scratch, so
      you don't have to create manually all the excluded directories.

   * ``-R /``
      Specifies the root directory for saving or restoring files. By
      default this points to the current working directory. We are
      doing a *system backup* here, so it will be the root directory.

   * ``-c `date -I`_data``
      This is the mandatory switch I talked of before, and it means
      to create a backup archive. For those who don't understand
      what follows, ```date -I``` is the shell's back tick
      expansion. In short, ``date -I`` will provide a date as
      YYYY-MM-DD format. With back ticks and used as a parameter,
      the output of the command will be used as a string of the
      parent command. This way you can create backup archives with
      the creation date embedded in the name. If you still don't
      understand what I'm talking about, try to run the following
      from the command line::

         echo "Today's date is `date -I`"

   * ``-Z file_pattern``
      Using normal file name globing you can specify patterns
      of files you want to store in your archive without
      compression. This only has sense if you use the ``-y``
      switch. Compressing compressed files only yields bigger files
      and wasted CPU time.

   * ``-P relative_path``
      With this switch you tell DAR_ which paths you don't want
      to store in your backup archive. Here you want to put the
      home directory (I'm the only user on this machine, there
      are a few more, but they are for testing/system purpose),
      system directories which aren't really physical files like
      ``proc``, other drives you may have mounted under ``mnt``
      (most notably the drive you are putting the backup file),
      etc, etc. Note that the paths you specify must be relative
      to the path specified by the ``-R`` switch.

   That wasn't so hard. Check DAR_'s manual page for more useful
   switches you might want to use. And here's the command line I'll
   be running as a plain user inside my home directory::

      dar -m 256 -y -s 600M -D -R /home/gregorio -c `date -I`_data \
         -Z "*.gz" -Z "*.bz2" -Z "*.zip" -Z "*.png" \
         -P instalacion_manual -P Mail/mail_pa_leer

   Nothing new under the sun. As you see, most of the command line
   is identical to the other one, I only change the name of the
   directories I want to exclude with ``-P`` and the root directory
   with the ``-R`` switch.


Making differential backups with DAR
====================================

   Once you have a full backup you can create a differential
   backup. The first differential backup has to be done using the
   full backup as reference. The following differential backups use
   the latest differential backup as reference. Here's the command
   line for a *system* differential backup::

      dar -m 256 -y -s 600M -D -R / -c `date -I`_diff -Z "*.gz" \
         -Z "*.bz2" -Z "*.zip" -Z "*.png" -P home/gregorio -P tmp \
         -P mnt -P dev/pts -P proc -P floppy -P burner -P cdrom \
         -A previous_backup

   * ``-c `date -I`_diff``
      I only change the name of the file, cosmetic purpose.

   * ``-A previous_backup``
      This new switch is used to tell DAR_ where is to be found
      the previous backup so it can create a differential backup
      instead of a full backup. The only thing you have to take
      care of is that you don't specify slice neither extension in
      the file name, otherwise DAR_ will make you an interactive
      question at the command line.

   The user command line is exactly the same. Here it is for
   completeness::

      dar -m 256 -y -s 600M -D -R /home/gregorio -c `date -I`_diff \
         -Z "*.gz" -Z "*.bz2" -Z "*.zip" -Z "*.png" \
         -P instalacion_manual -P Mail/mail_pa_leer -A previous_backup

   DAR_ has another nice feature we don't use here:
   *catalogues*. When you create a backup archive with DAR_,
   internally it contains the data plus a *catalogue*. This
   *catalogue* contains information about what files were saved,
   their dates, their compressed size, etc. You can extract the
   *catalogue* and store it separately. Why would you want to do
   this? To set up networked differential backups.

   In order to create a differential backup, you need to provide the
   previous backup so DAR_ can decide which files have changed or
   not. Doing this can be expensive in bandwidth if you work with a
   network. Instead, after you create a backup, you can extract the
   *catalogue* and send it to the machine doing the backups. Next
   time, you can use this file with the ``-A`` switch, and it will
   all work as if the complete file was there.

   This can be also useful if you use slices, because the *catalogue*
   is created from the first and last slice. It's more comfortable
   to pass a single file to the backup command rather than having
   to carry the disks of your previous backup with you.


Configurando algunos scripts para automatizar el proceso
========================================================

   As said before, now it's the time to put our backup solution
   under cron.  Place the following executable script for *system*
   backup under ``/root/dar_backup.sh``::

      #!/bin/sh
      
      DIR=/oldg/backup
      FILE=${DIR}/`/bin/date -I`_data
      # Commands
      /usr/local/bin/dar -m 256 -y -s 600M -D -R / -c $FILE -Z "*.gz" \
         -Z "*.bz2" -Z "*.zip" -Z "*.png" -P home/gregorio -P tmp \
         -P mnt -P dev/pts -P proc -P floppy -P burner \
         -P cdrom > /dev/null
      /usr/local/bin/dar -t $FILE > /dev/null
      /usr/bin/find $DIR -type f -exec chown .gregorio \{\} \;
      /usr/bin/find $DIR -type f -exec chmod 440 \{\} \;

   Some things to notice:

   * DIR is the variable which holds the destination directory.

   * FILE will hold the path to today's backup file.

   * I use full paths for the commands because my root account
     doesn't have all of them included in the default
     environment. This is potentially a security risk. Ideally you
     would like to compile DAR_ as root and keep your binaries where
     you make them so nobody can touch them. And run Tripwire_ over
     them too.

   * DAR_ generates statistics after each run. We don't want them
     in our cron because it will generate unnecessary mail. Only
     ``stdout`` is redirected to ``/dev/null``. Errors will be
     reported and a mail generated if something goes wrong.

   * The last two ``find`` commands are optional. I use them to
     change file ownership to a normal user, which will later create
     the backup.  Again, another security risk. root should backup
     that from root, and users should backup their stuff. But with
     a mono user system, I don't care. If some intruder is good
     enough to go through my firewall and account passwords to take
     a look at my backups, I'm already screwed.

   Now place the following nearly identical script for differential
   backups under ``/root/dar_diff.sh``::

      #!/bin/sh
      
      DIR=/oldg/backup
      FILE=${DIR}/`/bin/date -I`_diff
      PREV=`/bin/ls $DIR/*.dar|/usr/bin/tail -n 1|/usr/bin/awk -F '.' '{print $1;}'`
      /usr/local/bin/dar -m 256 -y -s 600M -D -R / -c $FILE -Z "*.gz" \
         -Z "*.bz2" -Z "*.zip" -Z "*.png" -P home/gregorio -P tmp -P mnt \
         -P dev/pts -P proc -P floppy -P burner -P cdrom -A $PREV > /dev/null
      /usr/local/bin/dar -t $FILE > /dev/null
      /usr/bin/find $DIR -type f -exec chown .gregorio \{\} \;
      /usr/bin/find $DIR -type f -exec chmod 440 \{\} \;

   The only two changes are the addition of the ``-A`` switch and
   the generation of the PREV variable with a complicated command
   line. Let's see what this command line does:

   * First the ``ls`` command creates a list of the files with
     ``.dar`` extension in the backup directory. This output is
     piped to the next command.

   * By default ``ls`` displays files alphabetically. ``tail``
     is used to get the last file with the ``-n 1`` switch, which
     says to display only the last line. Again, the last filename
     is piped to the next command.

   * DAR_ wants to operate on filenames without slice number and
     extension. This means that if we don't get rid of the tail,
     DAR_ will stop the operation and ask an interactive question to
     the user, defeating the purpose of automation. We separate the
     complete filename with ``awk``. The ``awk`` command separates
     the string at the dots, and prints the first column. The result
     is the base name we want to pass DAR_.

   We only have to put these two scripts under cron control. This
   is what we have to type after ``crontab -e``::

      15 0 2-31 * * ./dar_diff.sh
      15 0 1    * * ./dar_backup.sh

   Look up in ``man -S 5 crontab`` the syntax of the command. In
   short, those two lines tell cron to run the scripts 15 minutes
   past midnight. ``dar_backup.sh`` will be run only the first day
   of the month. The other script will be run all the other days.

   Here are the backup scripts for your users. They are the same,
   changing only switches to the DAR_ command and paths::

      #!/bin/sh
      # dar_backup.sh
      
      DIR=/oldg/backup_gregorio
      FILE=${DIR}/`/bin/date -I`_data
      # Commands
      /usr/local/bin/dar -m 256 -y -s 600M -D -R /home/gregorio -c $FILE \
         -Z "*.gz" -Z "*.bz2" -Z "*.zip" -Z "*.png" \
         -P instalacion_manual -P Mail/mail_pa_leer > /dev/null
      /usr/local/bin/dar -t $FILE > /dev/null
      /usr/bin/find $DIR -type f -exec chmod 400 \{\} \;
      
      #!/bin/sh
      # dar_diff.sh
      
      DIR=/oldg/backup_gregorio
      FILE=${DIR}/`/bin/date -I`_diff
      PREV=`/bin/ls $DIR/*.dar|/usr/bin/tail -n 1|/usr/bin/awk -F '.' '{print $1;}'`
      /usr/local/bin/dar -m 256 -y -s 600M -D -R /home/gregorio -c $FILE \
         -Z "*.gz" -Z "*.bz2" -Z "*.zip" -Z "*.zip" \
         -P instalacion_manual -P Mail/mail_pa_leer -A $PREV > /dev/null
      /usr/local/bin/dar -t $FILE > /dev/null
      /usr/bin/find $DIR -type f -exec chmod 400 \{\} \;

   Don't forget to add the required crontab entries for your user
   pointing to the appropriate path.
      

Recovering your backup to a clean machine
=========================================

   When the time comes to restore your backup, depending on what you
   saved you will have a full backup of one month plus differential
   backups up to the last time you managed to make. The restoration
   process is very simple, it's the same as described on the first
   chapter (`Simple DAR usage`_), only you have to do it first for
   the full backup, and then for the differential ones.  This can
   be boring, so here's another shell script you can save with your
   backup files::

      #!/bin/sh

      if [ -n "$3" ]; then
         CMD="$1"
         INPUT="$2_data"
         FS_ROOT="$3"
         $CMD -x "$INPUT" -w -R "$FS_ROOT"
         for file in ${INPUT:0:8}*_diff*; do
            $CMD -x "${file:0:15}" -w -R "$FS_ROOT"
         done
         echo "All done."
      else
         echo "Not enough parameters.
      
      Usage: script dar_location base_full_backup directory
      
      Where dar_location is a path to a working dar binary, base_full_backup
      is a date in the format 'YYYY-MM-DD', and directory is the place where
      you want to put the restored data, usually '/' when run as root."
      fi

   The script is pretty self explicative. The only things you
   would care is the ``-w`` switch, which tells DAR_ to overwrite
   found files. This is necessary for differential backups. Oh,
   and place the script in the same directory where you put your
   backup files. Here's an usage example::

      ./recover.sh /usr/local/bin/dar 2003-10-01 /tmp/temp_path/

   Try to run that as a normal user with a few of your backup
   files. You can put the result in a temporary directory, so the
   nice thing is you don't have to wipe your hard disk to test it.


Adding checks to the backup scripts
===================================

   Denis Corbin suggests that the scripts creating the backups could
   verify the exit status of the DAR_ command. For the purpose of
   these very simple scripts this is not critical because DAR_
   itself will bail out with an error message, and cron will
   report any output through mail (something which doesn't happen
   if everything goes right).

   However, testing the exit status can be useful if you are testing
   the scripts interactively and want to know which commands are
   executed::

      #!/bin/sh
      
      DIR=/oldg/backup
      FILE=${DIR}/`/bin/date -I`_data
      # Commands
      if /usr/local/bin/dar -m 256 -y -s 600M -D -R / -c $FILE -Z "*.gz" \
            -Z "*.bz2" -Z "*.zip" -Z "*.png" -P home/gregorio -P tmp \
            -P mnt -P dev/pts -P proc -P floppy -P burner \
            -P cdrom > /dev/null ; then
         if /usr/local/bin/dar -t $FILE > /dev/null ; then
            echo "Archive created and successfully tested."
         else
            echo "Archive created but test FAILED."
         fi
      else
         echo "Archive creating FAILED."
      fi
      /usr/bin/find $DIR -type f -exec chown .gregorio \{\} \;
      /usr/bin/find $DIR -type f -exec chmod 440 \{\} \;

   You can test this version easily running the script and killing
   the DAR_ process from another terminal or console with ``killall
   dar``. That will force the termination of the DAR_ process and
   you will see that one of the failure branches is reached in the
   backup script.

   Another possible use of testing the status code could be to
   remove incomplete archives from the hard disk if something
   went wrong, trigger additional external commands when something
   fails, or avoid testing the created archive when you know that
   the first command already failed. The latter can be done easily
   concatenating both the creation and testing commands with ``&&``
   in a single line. That will tell the shell to run both commands
   as a sequence and avoid running the second if the first failed.

   However, if a power failure happens in the middle of a backup,
   this version of the script would still leave dangling invalid
   archives. To prevent this you could enhance the script to do
   a *positive verification*. This means creating the backup in
   a temporary directory along with a ``*.valid`` file in the
   successful branch of the script is reached.

   With this strategy, another cron script monitoring the directory
   where the temporary backups are placed would move to the final
   backup directory those archives which have a ``*.valid`` file,
   deleting all other whose last modification timestamp is older
   than one hour.
   

Ideas for the future
====================

   I'm not going to implement these soon, because I'm very lazy,
   but if you are one of those hyperactive hackers, here are some
   things which would be nice:

   * Unify both the main and differential scripts into a single one,
     so if the script is run and there is no main backup for the
     current month, the main backup will be created. Useful if
     your machine happens to be down during the time the monthly
     backup is done.

   * Update the scripts to generate daily a CDROM image with
     cdrecord_ and burn it automatically to a rewritable disc
     placed in your machine. So if your whole hard disk is trashed,
     you still have the last backup on removable media. Of course,
     this is limited and cannot be automated if your backup spans
     more than one CDROM. Do the same for ZIP/JAZZ/whatever you have.

   * Integration of generated backups with a mini Knoppix_ bootable
     distribution. Or any other floppy distribution which can be
     booted from CDROM. So you have a recovery CDROM with tools to
     format your hard disk, and near it you have a fresh backup to
     restore a working machine.

   * Synchronisation of backup directories through Internet with
     remote hosts. Even if the whole machine is burnt physically
     along with your house, you have up to date backups somewhere
     else. Could be done easily with programs like rsync_ through
     ssh_ running in a cron job.
   

The end
=======

   And that's the whole *magic*. If you have problems, something
   is unclear or wrong (which is worse), drop me an email. If you
   find this document useful and want to translate it, send me a
   translation of the file ``source.en.txt`` so I can distribute
   it along this version and users can find easily their localized
   version. Talking about locations, you should be able to get
   the source of this document from my personal home page (link
   `at the beginning of the document`__).

__ `DAR differential backup mini-howto -EN-`_

   Enjoy!
